{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7494554,"datasetId":3274009,"databundleVersionId":7587411},{"sourceType":"kernelVersion","sourceId":258966953}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Instalations\n!python -m pip install --upgrade pip\n!pip install yfinance==0.2.59\n!pip install curl-cffi\n#!pip install yfinance","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-09-08T15:24:41.678381Z","iopub.execute_input":"2025-09-08T15:24:41.678686Z","iopub.status.idle":"2025-09-08T15:25:22.578434Z","shell.execute_reply.started":"2025-09-08T15:24:41.678664Z","shell.execute_reply":"2025-09-08T15:25:22.577427Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-25.2-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.2\nCollecting yfinance==0.2.59\n  Downloading yfinance-0.2.59-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.2.3)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.32.4)\nRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (0.0.11)\nRequirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (4.3.8)\nRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2025.2)\nRequirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.4.6)\nRequirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (3.18.1)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (4.13.4)\nRequirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (0.11.4)\nCollecting protobuf<6,>=5.29.0 (from yfinance==0.2.59)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (15.0.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (4.14.0)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (1.17.1)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (2025.6.15)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance==0.2.59) (2.22)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance==0.2.59) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (2.5.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.5->yfinance==0.2.59) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->yfinance==0.2.59) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\nDownloading yfinance-0.2.59-py2.py3-none-any.whl (117 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\nInstalling collected packages: protobuf, yfinance\n\u001b[2K  Attempting uninstall: protobuf\n\u001b[2K    Found existing installation: protobuf 3.20.3\n\u001b[2K    Uninstalling protobuf-3.20.3:\n\u001b[2K      Successfully uninstalled protobuf-3.20.3━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n\u001b[2K  Attempting uninstall: yfinance━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n\u001b[2K    Found existing installation: yfinance 0.2.63 \u001b[32m0/2\u001b[0m [protobuf]\n\u001b[2K    Uninstalling yfinance-0.2.63:━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n\u001b[2K      Successfully uninstalled yfinance-0.2.630m \u001b[32m0/2\u001b[0m [protobuf]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [yfinance]1/2\u001b[0m [yfinance]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-5.29.5 yfinance-0.2.59\nRequirement already satisfied: curl-cffi in /usr/local/lib/python3.11/dist-packages (0.11.4)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl-cffi) (1.17.1)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl-cffi) (2025.6.15)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl-cffi) (2.22)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Imports\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport requests\nimport warnings\n\n\nfrom tqdm.auto import tqdm\nfrom curl_cffi import requests\nfrom kaggle_secrets import UserSecretsClient\n\n# load secret key\nuser_secrets = UserSecretsClient()\nforex_api = user_secrets.get_secret(\"Forex data API\")\n\n# disable warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T15:25:22.580550Z","iopub.execute_input":"2025-09-08T15:25:22.580937Z","iopub.status.idle":"2025-09-08T15:25:24.293649Z","shell.execute_reply.started":"2025-09-08T15:25:22.580887Z","shell.execute_reply":"2025-09-08T15:25:24.292633Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Forex data","metadata":{}},{"cell_type":"code","source":"class ForexDataHandler:\n    def __init__(self, main_currencies=['PLN', 'EUR'], additional_currencies=['CZK', 'HUF', 'USD', 'CHF', 'GBP', 'JPY']):\n        self.main_currencies = main_currencies\n        self.additional_currencies = additional_currencies\n        self.session = requests.Session(impersonate=\"chrome\", timeout=5)\n\n    def download_data(self, cur_1, cur_2, t_period='5d', t_interval='1m'):\n        symbol = f'{cur_1}{cur_2}=X'\n        data = yf.Ticker(symbol, session=self.session)\n        f_data = data.history(period=t_period, interval=t_interval)\n\n        mask = f_data.ne(0).any(axis=0)\n        f_data = f_data.loc[:, mask]\n\n        f_data.reset_index(inplace=True)\n        f_data.rename(columns={\n            'Datetime': 'timestamp',\n            'Open': f'{cur_1}{cur_2}_OPEN',\n            'High': f'{cur_1}{cur_2}_HIGH',\n            'Low': f'{cur_1}{cur_2}_LOW',\n            'Close': f'{cur_1}{cur_2}_CLOSE'\n        }, inplace=True)\n\n        f_data['timestamp'] = f_data['timestamp'].apply(lambda x: x.timestamp()).astype(int)\n        f_data.set_index('timestamp', inplace=True)\n        return f_data\n\n    def update_forex_data(self, old_data_path, save_path='forex_data.feather'):\n        old_data = pd.read_feather(old_data_path)\n        old_data.set_index('timestamp', inplace=True)\n\n        forex_data = self.download_data('EUR', 'PLN')\n\n        for main in self.main_currencies:\n            for add in self.additional_currencies:\n                if main == add:\n                    continue\n                try:\n                    temp_data = self.download_data(main, add)\n                    forex_data = forex_data.join(temp_data)\n                except Exception as e:\n                    print(f'Error: {e}, cur1: {main}, cur2:{add}')\n\n        forex_data = pd.concat([forex_data, old_data])\n\n        forex_data.reset_index(inplace=True)\n        forex_data.drop_duplicates(subset=['timestamp'], inplace=True)\n        forex_data.sort_index(inplace=True)\n        \n        forex_data.to_feather(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T15:25:24.294542Z","iopub.execute_input":"2025-09-08T15:25:24.295078Z","iopub.status.idle":"2025-09-08T15:25:24.307193Z","shell.execute_reply.started":"2025-09-08T15:25:24.295021Z","shell.execute_reply":"2025-09-08T15:25:24.305850Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"forex_path = '/kaggle/input/forex-data-downloader/forex_data.feather'\n\nhandler = ForexDataHandler()\nhandler.update_forex_data(forex_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T15:25:24.309132Z","iopub.execute_input":"2025-09-08T15:25:24.309405Z","iopub.status.idle":"2025-09-08T15:25:32.093576Z","shell.execute_reply.started":"2025-09-08T15:25:24.309381Z","shell.execute_reply":"2025-09-08T15:25:32.092542Z"}},"outputs":[{"name":"stdout","text":"Error: 'timestamp', cur1: PLN, cur2:HUF\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Economic calendar","metadata":{}},{"cell_type":"code","source":"class EconomicDataHandler:\n    def __init__(\n        self,\n        start_date: str = \"2020-01-01\",\n        end_date: pd.Timestamp = pd.Timestamp.today().normalize(),\n        chunk_days: int = 30,\n        save_path: str = None\n    ):\n        self.start_date = pd.to_datetime(start_date)\n        self.end_date = end_date\n        self.chunk_delta = pd.Timedelta(days=chunk_days)\n        self.save_path = save_path\n        self.date_ranges = self._generate_date_ranges()\n        self.clean_chunks = []\n\n    def _generate_date_ranges(self):\n        # Split the full interval into successive (start, end) pairs\n        ranges = []\n        curr = self.start_date\n        \n        while curr <= self.end_date:\n            end = min(curr + self.chunk_delta, self.end_date)\n            ranges.append((curr, end))\n            curr = curr + self.chunk_delta\n\n        return ranges\n\n    def _fetch_range(self, start: pd.Timestamp, to: pd.Timestamp) -> pd.DataFrame:\n        # Download raw events JSON and convert to DataFrame.\n        url = \"https://economic-calendar.tradingview.com/events\"\n        params = {\n            \"from\": start.date().isoformat(), \n            \"to\": to.date().isoformat()\n            }\n        headers = {\"Origin\": \"https://www.tradingview.com\"}\n\n        resp = requests.get(url, headers=headers, params=params)\n        resp.raise_for_status()\n        data = resp.json().get(\"result\", [])\n\n        return pd.DataFrame(data)\n\n    def _clean_df(self, df: pd.DataFrame) -> pd.DataFrame:\n\n        # Fill missing values in referenceDate and create new \"Timestamp\" column\n        df[\"referenceDate\"] = df[\"referenceDate\"].fillna(df[\"date\"])\n        df['referenceDate'] = pd.to_datetime(df[\"referenceDate\"], format='mixed', yearfirst=True)\n        df['timestamp'] = df['referenceDate'].apply(lambda x: x.timestamp()).astype(int)\n\n        # Drop unimportant columns, duplicates and rows without crucial data\n        calendar_drop = ['id', 'period', 'source', 'ticker', 'scale', 'category',\n                            'actualRaw', 'previousRaw', 'forecastRaw', 'source_url'\n                        ]\n        df.drop(calendar_drop, axis=1, inplace=True)\n        df.dropna(subset=['actual'], inplace=True)\n        df.drop_duplicates(subset=['title', 'date', 'indicator', 'country', 'referenceDate', 'actual'], inplace=True, keep='last')\n\n        return df\n\n    def download(self) -> pd.DataFrame:\n        # Main entry: fetch all data, clean and save if requested\n        for start, to in tqdm(self.date_ranges, desc=\"Downloading chunks\"):\n            try:\n                raw = self._fetch_range(start, to)\n                clean = self._clean_df(raw)\n                self.clean_chunks.append(clean)\n            except Exception as e:\n                print(f\"Error fetching {start.date()}→{to.date()}: {e}\")\n\n        data = pd.concat(self.clean_chunks, ignore_index=True)\n        data.reset_index(inplace=True, drop=True)\n\n        if self.save_path:\n            data.to_feather(self.save_path)\n        return data","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Economic_handler = EconomicDataHandler()\neconomic_data = Economic_handler.download()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"forex_data = pd.read_feather('/kaggle/input/forex-data-gatherer/forex_data.feather')","metadata":{"execution":{"iopub.execute_input":"2024-02-10T20:25:20.639842Z","iopub.status.busy":"2024-02-10T20:25:20.639194Z","iopub.status.idle":"2024-02-10T20:25:21.260039Z","shell.execute_reply":"2024-02-10T20:25:21.258998Z","shell.execute_reply.started":"2024-02-10T20:25:20.639796Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Economic calendar d.aggregateta\neconomic_df = pd.read_feather('/kaggle/input/economic-calendar-data/economic_data.feather')","metadata":{"execution":{"iopub.execute_input":"2024-02-10T20:25:21.264941Z","iopub.status.busy":"2024-02-10T20:25:21.264592Z","iopub.status.idle":"2024-02-10T20:25:21.717665Z","shell.execute_reply":"2024-02-10T20:25:21.716272Z","shell.execute_reply.started":"2024-02-10T20:25:21.264909Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"economic_poland = economic_df[economic_df['country']=='PL'].copy()\neconomic_poland.reset_index(inplace=True)\neconomic_poland.drop('index', inplace=True, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fix some data(sometimes records from previous months are saved next month as duplicates)\neconomic_poland = economic_df[economic_df['country']=='PL'].copy()\n\nmask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\nfor idx, [index, row] in enumerate(economic_poland.loc[mask].iterrows()):\n    try:\n        pair = economic_poland.loc[mask].iloc[idx+1]\n        if all(row[['date', 'title']] == pair[['date', 'title']]):\n            if row['actual'] == pair['previous']:\n                new_date = pd.to_datetime(row['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == row['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[index], ['date']] = new_date.strftime('%Y-%m-%d')\n            else:\n                new_date = pd.to_datetime(pair['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == pair['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[pair.name], ['date']] = new_date.strftime('%Y-%m-%d')\n    except Exception as e:\n        continue\n        #print(e)","metadata":{"execution":{"iopub.execute_input":"2024-02-10T20:52:36.249431Z","iopub.status.busy":"2024-02-10T20:52:36.249005Z","iopub.status.idle":"2024-02-10T20:52:36.319587Z","shell.execute_reply":"2024-02-10T20:52:36.318717Z","shell.execute_reply.started":"2024-02-10T20:52:36.249396Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create new df with continues range of dates and all indicator values in any day\n\ndf_pivot = economic_poland.pivot(columns='title', values='actual')\n\n#merge tables to update dates\nmerged = df_pivot.merge(economic_poland, left_index=True, right_index=True)\nmerged.drop(['title', 'country', 'indicator', 'comment','actual', 'previous', 'forecast', 'importance'], axis=1, inplace=True)\nmerged.reset_index(inplace=True)\n\n#create continues dates from oldest to newest \nidx = pd.date_range(merged.date.min(), merged.date.max())\nidx = idx.strftime('%Y-%m-%d')\n\n#create new dataframe with full set of date range\nnew_df = pd.DataFrame(index=idx, columns=merged.columns)\nnew_df.drop('date', axis=1, inplace=True)\n\n# change date column to str to be merge\nmerged['date'] = merged['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n\n#merge both dataframes table with values in full set of ranges\nfullset = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset.dropna(axis=1, how='all', inplace=True)\n\n#fill all nans with values from previous rows(newest)\nfullset = fullset.ffill()\n\n#drop duplicates\nfullset.drop_duplicates(subset=['date'], inplace=True, keep='last')\nfullset.set_index('date', inplace=True)\nfullset.drop('index', inplace=True, axis=1)\n\n#fill rest of nan values(oldest data) with oldest 'previous' value from main df - check if it is not bettter to leave nan\nfor col in fullset.columns:\n    if pd.isna(fullset[col].iloc[0]):\n        value = economic_poland.loc[economic_poland['title'] == col].iloc[0]['previous']\n        fullset[col] = fullset[col].fillna(value)\n        \n#check if last row in our dataframe is correct\ntest_df = pd.DataFrame()\nfor title in economic_poland['title'].unique():\n    test_df[title] = [economic_poland[economic_poland[\"title\"]==title].iloc[-1][\"actual\"]]\n    \ntest_true = fullset.drop('timestamp', axis=1).iloc[-1] == test_df\nprint(test_true.iloc[0].unique()) #it should only contain \"True\" values","metadata":{"execution":{"iopub.execute_input":"2024-02-10T21:26:24.195350Z","iopub.status.busy":"2024-02-10T21:26:24.194963Z","iopub.status.idle":"2024-02-10T21:26:24.690134Z","shell.execute_reply":"2024-02-10T21:26:24.688841Z","shell.execute_reply.started":"2024-02-10T21:26:24.195317Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset","metadata":{"execution":{"iopub.execute_input":"2024-02-10T21:26:28.251194Z","iopub.status.busy":"2024-02-10T21:26:28.250797Z","iopub.status.idle":"2024-02-10T21:26:28.288763Z","shell.execute_reply":"2024-02-10T21:26:28.287690Z","shell.execute_reply.started":"2024-02-10T21:26:28.251167Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"error = []\nfor title in economic_poland.title.unique():\n    all_rows = economic_poland[economic_poland.title == title]\n    for index, [idx, row] in enumerate(all_rows.iterrows()):\n        try:\n            now = row['date']\n            until = pd.to_datetime(all_rows.iloc[index+1]['date'])\n            until = until - pd.Timedelta(days=1)\n            until = until.strftime('%Y-%m-%d')\n        except:\n            pass\n        if now > until:\n            temp1 = now\n            now = until\n            until = temp1\n        actual = row['actual']\n        if all(actual != fullset.loc[now:until][indicator]):\n            error.append([now, until, actual, fullset.loc[now][indicator], indicator])","metadata":{"execution":{"iopub.execute_input":"2024-02-10T21:15:57.223961Z","iopub.status.busy":"2024-02-10T21:15:57.223633Z","iopub.status.idle":"2024-02-10T21:15:57.245432Z","shell.execute_reply":"2024-02-10T21:15:57.244018Z","shell.execute_reply.started":"2024-02-10T21:15:57.223934Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#merge both dataframes table with values in full set of ranges\nfullset2 = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset2.dropna(axis=1, how='all', inplace=True)\nfullset2.set_index('date', inplace=True)","metadata":{"execution":{"iopub.execute_input":"2023-05-28T21:54:37.550906Z","iopub.status.busy":"2023-05-28T21:54:37.550063Z","iopub.status.idle":"2023-05-28T21:54:38.061824Z","shell.execute_reply":"2023-05-28T21:54:38.060676Z","shell.execute_reply.started":"2023-05-28T21:54:37.550852Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"execution":{"iopub.execute_input":"2023-05-28T22:09:16.543059Z","iopub.status.busy":"2023-05-28T22:09:16.542534Z","iopub.status.idle":"2023-05-28T22:09:16.555186Z","shell.execute_reply":"2023-05-28T22:09:16.553738Z","shell.execute_reply.started":"2023-05-28T22:09:16.543011Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\neconomic_poland.loc[mask]","metadata":{"execution":{"iopub.execute_input":"2023-05-28T23:44:29.812726Z","iopub.status.busy":"2023-05-28T23:44:29.810661Z","iopub.status.idle":"2023-05-28T23:44:29.861482Z","shell.execute_reply":"2023-05-28T23:44:29.860474Z","shell.execute_reply.started":"2023-05-28T23:44:29.812654Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"economic_poland[economic_poland['date'] == '2016-03-15']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final'].dropna()[0:20]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Forex data\nforex_df = pd.read_excel('/kaggle/input/forex-data-gatherer/FOREX_DATA.xlsx')\n\nforex_df['Datetime'] = pd.to_datetime(forex_df['Datetime'], dayfirst=True)\nforex_df = dataframe.sort_values(by='Datetime', ascending=False)\nforex_df['Datetime'] = forex_df[\"Datetime\"].dt.strftime('%d-%m-%Y %H:%M:%S %z')\nforex_df.set_index('Datetime', inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_df = dataframe.join(calendar_df).drop_duplicates()\njoin_df = join_df[~join_df.index.duplicated(keep='first')]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_df.loc['28-03-2023 07:00:00 +0100']","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}