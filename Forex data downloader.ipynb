{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7494554,"datasetId":3274009,"databundleVersionId":7587411},{"sourceType":"kernelVersion","sourceId":292344737}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Instalations\n!python -m pip install --upgrade pip\n!pip install yfinance==0.2.59\n!pip install curl-cffi\n#!pip install yfinance","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-26T21:47:43.911349Z","iopub.execute_input":"2026-01-26T21:47:43.911864Z","iopub.status.idle":"2026-01-26T21:47:58.282125Z","shell.execute_reply.started":"2026-01-26T21:47:43.911829Z","shell.execute_reply":"2026-01-26T21:47:58.280255Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pip-25.3\nCollecting yfinance==0.2.59\n  Downloading yfinance-0.2.59-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (2.2.2)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (2.0.2)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (2.32.5)\nRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (0.0.12)\nRequirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (4.5.1)\nRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (2025.2)\nRequirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (2.4.6)\nRequirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (3.18.2)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (4.13.5)\nRequirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (0.13.0)\nRequirement already satisfied: protobuf<6,>=5.29.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (5.29.5)\nRequirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.12/dist-packages (from yfinance==0.2.59) (15.0.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (2.8)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (4.15.0)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (2.0.0)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (2026.1.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance==0.2.59) (2.23)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance==0.2.59) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance==0.2.59) (2.6.3)\nDownloading yfinance-0.2.59-py2.py3-none-any.whl (117 kB)\nInstalling collected packages: yfinance\n  Attempting uninstall: yfinance\n    Found existing installation: yfinance 0.2.66\n    Uninstalling yfinance-0.2.66:\n      Successfully uninstalled yfinance-0.2.66\nSuccessfully installed yfinance-0.2.59\nRequirement already satisfied: curl-cffi in /usr/local/lib/python3.12/dist-packages (0.13.0)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl-cffi) (2.0.0)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl-cffi) (2026.1.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl-cffi) (2.23)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Imports\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport requests\nimport warnings\n\n\nfrom tqdm.auto import tqdm\nfrom curl_cffi import requests\nfrom kaggle_secrets import UserSecretsClient\n\n# load secret key\nuser_secrets = UserSecretsClient()\nforex_api = user_secrets.get_secret(\"Forex data API\")\n\n# disable warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T21:47:58.284132Z","iopub.execute_input":"2026-01-26T21:47:58.285084Z","iopub.status.idle":"2026-01-26T21:48:00.194215Z","shell.execute_reply.started":"2026-01-26T21:47:58.285049Z","shell.execute_reply":"2026-01-26T21:48:00.193599Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Forex data","metadata":{}},{"cell_type":"code","source":"class ForexDataHandler:\n    def __init__(self, main_currencies=['PLN', 'EUR'], additional_currencies=['CZK', 'HUF', 'USD', 'CHF', 'GBP', 'JPY']):\n        self.main_currencies = main_currencies\n        self.additional_currencies = additional_currencies\n        self.session = requests.Session(impersonate=\"chrome\", timeout=5)\n\n    def download_data(self, cur_1, cur_2, t_period='5d', t_interval='1m'):\n        symbol = f'{cur_1}{cur_2}=X'\n        data = yf.Ticker(symbol, session=self.session)\n        f_data = data.history(period=t_period, interval=t_interval)\n\n        mask = f_data.ne(0).any(axis=0)\n        f_data = f_data.loc[:, mask]\n\n        f_data.reset_index(inplace=True)\n        f_data.rename(columns={\n            'Datetime': 'timestamp',\n            'Open': f'{cur_1}{cur_2}_OPEN',\n            'High': f'{cur_1}{cur_2}_HIGH',\n            'Low': f'{cur_1}{cur_2}_LOW',\n            'Close': f'{cur_1}{cur_2}_CLOSE'\n        }, inplace=True)\n\n        f_data['timestamp'] = f_data['timestamp'].apply(lambda x: x.timestamp()).astype(int)\n        f_data.set_index('timestamp', inplace=True)\n        return f_data\n\n    def update_forex_data(self, old_data_path, save_path='forex_data.feather'):\n        old_data = pd.read_feather(old_data_path)\n        old_data.set_index('timestamp', inplace=True)\n\n        forex_data = self.download_data('EUR', 'PLN')\n\n        for main in self.main_currencies:\n            for add in self.additional_currencies:\n                if main == add:\n                    continue\n                try:\n                    temp_data = self.download_data(main, add)\n                    forex_data = forex_data.join(temp_data)\n                except Exception as e:\n                    print(f'Error: {e}, cur1: {main}, cur2:{add}')\n\n        forex_data = pd.concat([forex_data, old_data])\n\n        forex_data.reset_index(inplace=True)\n        forex_data.drop_duplicates(subset=['timestamp'], inplace=True)\n        forex_data.sort_index(inplace=True)\n        \n        forex_data.to_feather(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T21:48:00.195162Z","iopub.execute_input":"2026-01-26T21:48:00.195640Z","iopub.status.idle":"2026-01-26T21:48:00.208312Z","shell.execute_reply.started":"2026-01-26T21:48:00.195606Z","shell.execute_reply":"2026-01-26T21:48:00.207179Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"forex_path = '/kaggle/input/forex-data-downloader/forex_data.feather'\n\nhandler = ForexDataHandler()\nhandler.update_forex_data(forex_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T21:48:00.210142Z","iopub.execute_input":"2026-01-26T21:48:00.210613Z","iopub.status.idle":"2026-01-26T21:48:06.445263Z","shell.execute_reply.started":"2026-01-26T21:48:00.210575Z","shell.execute_reply":"2026-01-26T21:48:06.443977Z"}},"outputs":[{"name":"stderr","text":"$PLNHUF=X: possibly delisted; no price data found  (period=5d)\n","output_type":"stream"},{"name":"stdout","text":"Error: 'timestamp', cur1: PLN, cur2:HUF\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Economic calendar","metadata":{}},{"cell_type":"code","source":"class EconomicDataHandler:\n    def __init__(\n        self,\n        start_date: str = \"2020-01-01\",\n        end_date: pd.Timestamp = pd.Timestamp.today().normalize(),\n        chunk_days: int = 30,\n        save_path: str = None\n    ):\n        self.start_date = pd.to_datetime(start_date)\n        self.end_date = end_date\n        self.chunk_delta = pd.Timedelta(days=chunk_days)\n        self.save_path = save_path\n        self.date_ranges = self._generate_date_ranges()\n        self.clean_chunks = []\n\n    def _generate_date_ranges(self):\n        # Split the full interval into successive (start, end) pairs\n        ranges = []\n        curr = self.start_date\n        \n        while curr <= self.end_date:\n            end = min(curr + self.chunk_delta, self.end_date)\n            ranges.append((curr, end))\n            curr = curr + self.chunk_delta\n\n        return ranges\n\n    def _fetch_range(self, start: pd.Timestamp, to: pd.Timestamp) -> pd.DataFrame:\n        # Download raw events JSON and convert to DataFrame.\n        url = \"https://economic-calendar.tradingview.com/events\"\n        params = {\n            \"from\": start.date().isoformat(), \n            \"to\": to.date().isoformat()\n            }\n        headers = {\"Origin\": \"https://www.tradingview.com\"}\n\n        resp = requests.get(url, headers=headers, params=params)\n        resp.raise_for_status()\n        data = resp.json().get(\"result\", [])\n\n        return pd.DataFrame(data)\n\n    def _clean_df(self, df: pd.DataFrame) -> pd.DataFrame:\n\n        # Fill missing values in referenceDate and create new \"Timestamp\" column\n        df[\"referenceDate\"] = df[\"referenceDate\"].fillna(df[\"date\"])\n        df['referenceDate'] = pd.to_datetime(df[\"referenceDate\"], format='mixed', yearfirst=True)\n        df['timestamp'] = df['referenceDate'].apply(lambda x: x.timestamp()).astype(int)\n\n        # Drop unimportant columns, duplicates and rows without crucial data\n        calendar_drop = ['id', 'period', 'source', 'ticker', 'scale', 'category',\n                            'actualRaw', 'previousRaw', 'forecastRaw', 'source_url'\n                        ]\n        df.drop(calendar_drop, axis=1, inplace=True)\n        df.dropna(subset=['actual'], inplace=True)\n        df.drop_duplicates(subset=['title', 'date', 'indicator', 'country', 'referenceDate', 'actual'], inplace=True, keep='last')\n\n        return df\n\n    def download(self) -> pd.DataFrame:\n        # Main entry: fetch all data, clean and save if requested\n        for start, to in tqdm(self.date_ranges, desc=\"Downloading chunks\"):\n            try:\n                raw = self._fetch_range(start, to)\n                clean = self._clean_df(raw)\n                self.clean_chunks.append(clean)\n            except Exception as e:\n                print(f\"Error fetching {start.date()}→{to.date()}: {e}\")\n\n        data = pd.concat(self.clean_chunks, ignore_index=True)\n        data.reset_index(inplace=True, drop=True)\n\n        if self.save_path:\n            data.to_feather(self.save_path)\n        return data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Economic_handler = EconomicDataHandler()\neconomic_data = Economic_handler.download()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"forex_data = pd.read_feather('/kaggle/input/forex-data-gatherer/forex_data.feather')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Economic calendar d.aggregateta\neconomic_df = pd.read_feather('/kaggle/input/economic-calendar-data/economic_data.feather')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"economic_poland = economic_df[economic_df['country']=='PL'].copy()\neconomic_poland.reset_index(inplace=True)\neconomic_poland.drop('index', inplace=True, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fix some data(sometimes records from previous months are saved next month as duplicates)\neconomic_poland = economic_df[economic_df['country']=='PL'].copy()\n\nmask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\nfor idx, [index, row] in enumerate(economic_poland.loc[mask].iterrows()):\n    try:\n        pair = economic_poland.loc[mask].iloc[idx+1]\n        if all(row[['date', 'title']] == pair[['date', 'title']]):\n            if row['actual'] == pair['previous']:\n                new_date = pd.to_datetime(row['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == row['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[index], ['date']] = new_date.strftime('%Y-%m-%d')\n            else:\n                new_date = pd.to_datetime(pair['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == pair['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[pair.name], ['date']] = new_date.strftime('%Y-%m-%d')\n    except Exception as e:\n        continue\n        #print(e)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create new df with continues range of dates and all indicator values in any day\n\ndf_pivot = economic_poland.pivot(columns='title', values='actual')\n\n#merge tables to update dates\nmerged = df_pivot.merge(economic_poland, left_index=True, right_index=True)\nmerged.drop(['title', 'country', 'indicator', 'comment','actual', 'previous', 'forecast', 'importance'], axis=1, inplace=True)\nmerged.reset_index(inplace=True)\n\n#create continues dates from oldest to newest \nidx = pd.date_range(merged.date.min(), merged.date.max())\nidx = idx.strftime('%Y-%m-%d')\n\n#create new dataframe with full set of date range\nnew_df = pd.DataFrame(index=idx, columns=merged.columns)\nnew_df.drop('date', axis=1, inplace=True)\n\n# change date column to str to be merge\nmerged['date'] = merged['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n\n#merge both dataframes table with values in full set of ranges\nfullset = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset.dropna(axis=1, how='all', inplace=True)\n\n#fill all nans with values from previous rows(newest)\nfullset = fullset.ffill()\n\n#drop duplicates\nfullset.drop_duplicates(subset=['date'], inplace=True, keep='last')\nfullset.set_index('date', inplace=True)\nfullset.drop('index', inplace=True, axis=1)\n\n#fill rest of nan values(oldest data) with oldest 'previous' value from main df - check if it is not bettter to leave nan\nfor col in fullset.columns:\n    if pd.isna(fullset[col].iloc[0]):\n        value = economic_poland.loc[economic_poland['title'] == col].iloc[0]['previous']\n        fullset[col] = fullset[col].fillna(value)\n        \n#check if last row in our dataframe is correct\ntest_df = pd.DataFrame()\nfor title in economic_poland['title'].unique():\n    test_df[title] = [economic_poland[economic_poland[\"title\"]==title].iloc[-1][\"actual\"]]\n    \ntest_true = fullset.drop('timestamp', axis=1).iloc[-1] == test_df\nprint(test_true.iloc[0].unique()) #it should only contain \"True\" values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"error = []\nfor title in economic_poland.title.unique():\n    all_rows = economic_poland[economic_poland.title == title]\n    for index, [idx, row] in enumerate(all_rows.iterrows()):\n        try:\n            now = row['date']\n            until = pd.to_datetime(all_rows.iloc[index+1]['date'])\n            until = until - pd.Timedelta(days=1)\n            until = until.strftime('%Y-%m-%d')\n        except:\n            pass\n        if now > until:\n            temp1 = now\n            now = until\n            until = temp1\n        actual = row['actual']\n        if all(actual != fullset.loc[now:until][indicator]):\n            error.append([now, until, actual, fullset.loc[now][indicator], indicator])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#merge both dataframes table with values in full set of ranges\nfullset2 = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset2.dropna(axis=1, how='all', inplace=True)\nfullset2.set_index('date', inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\neconomic_poland.loc[mask]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"economic_poland[economic_poland['date'] == '2016-03-15']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final'].dropna()[0:20]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Forex data\nforex_df = pd.read_excel('/kaggle/input/forex-data-gatherer/FOREX_DATA.xlsx')\n\nforex_df['Datetime'] = pd.to_datetime(forex_df['Datetime'], dayfirst=True)\nforex_df = dataframe.sort_values(by='Datetime', ascending=False)\nforex_df['Datetime'] = forex_df[\"Datetime\"].dt.strftime('%d-%m-%Y %H:%M:%S %z')\nforex_df.set_index('Datetime', inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_df = dataframe.join(calendar_df).drop_duplicates()\njoin_df = join_df[~join_df.index.duplicated(keep='first')]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_df.loc['28-03-2023 07:00:00 +0100']","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}