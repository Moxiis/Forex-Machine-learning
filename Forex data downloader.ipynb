{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-30T22:25:17.423283Z",
     "iopub.status.busy": "2025-07-30T22:25:17.422997Z",
     "iopub.status.idle": "2025-07-30T22:25:50.339049Z",
     "shell.execute_reply": "2025-07-30T22:25:50.338097Z",
     "shell.execute_reply.started": "2025-07-30T22:25:17.423259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.2\n",
      "Collecting yfinance==0.2.59\n",
      "  Downloading yfinance-0.2.59-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.32.4)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (3.18.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (4.13.4)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (0.11.4)\n",
      "Collecting protobuf<6,>=5.29.0 (from yfinance==0.2.59)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (4.14.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (2025.6.15)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance==0.2.59) (2.22)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance==0.2.59) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (2.5.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.5->yfinance==0.2.59) (2022.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->yfinance==0.2.59) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\n",
      "Downloading yfinance-0.2.59-py2.py3-none-any.whl (117 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Installing collected packages: protobuf, yfinance\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 3.20.3\n",
      "\u001b[2K    Uninstalling protobuf-3.20.3:\n",
      "\u001b[2K      Successfully uninstalled protobuf-3.20.3━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: yfinance━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: yfinance 0.2.63 \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling yfinance-0.2.63:━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled yfinance-0.2.630m \u001b[32m0/2\u001b[0m [protobuf]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [yfinance]1/2\u001b[0m [yfinance]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-5.29.5 yfinance-0.2.59\n",
      "Requirement already satisfied: curl-cffi in /usr/local/lib/python3.11/dist-packages (0.11.4)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl-cffi) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl-cffi) (2025.6.15)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl-cffi) (2.22)\n"
     ]
    }
   ],
   "source": [
    "# Instalations\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install yfinance==0.2.59\n",
    "!pip install curl-cffi\n",
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from curl_cffi import requests\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# load secret key\n",
    "user_secrets = UserSecretsClient()\n",
    "forex_api = user_secrets.get_secret(\"Forex data API\")\n",
    "\n",
    "# disable warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ForexDataHandler:\n",
    "    def __init__(self, main_currencies=['PLN', 'EUR'], additional_currencies=['CZK', 'HUF', 'USD', 'CHF', 'GBP', 'JPY']):\n",
    "        self.main_currencies = main_currencies\n",
    "        self.additional_currencies = additional_currencies\n",
    "        self.session = requests.Session(impersonate=\"chrome\", timeout=5)\n",
    "\n",
    "    def download_data(self, cur_1, cur_2, t_period='5d', t_interval='1m'):\n",
    "        symbol = f'{cur_1}{cur_2}=X'\n",
    "        data = yf.Ticker(symbol, session=self.session)\n",
    "        f_data = data.history(period=t_period, interval=t_interval)\n",
    "\n",
    "        mask = f_data.ne(0).any(axis=0)\n",
    "        f_data = f_data.loc[:, mask]\n",
    "\n",
    "        f_data.reset_index(inplace=True)\n",
    "        f_data.rename(columns={\n",
    "            'Datetime': 'timestamp',\n",
    "            'Open': f'{cur_1}{cur_2}_OPEN',\n",
    "            'High': f'{cur_1}{cur_2}_HIGH',\n",
    "            'Low': f'{cur_1}{cur_2}_LOW',\n",
    "            'Close': f'{cur_1}{cur_2}_CLOSE'\n",
    "        }, inplace=True)\n",
    "\n",
    "        f_data['timestamp'] = f_data['timestamp'].apply(lambda x: x.timestamp()).astype(int)\n",
    "        f_data.set_index('timestamp', inplace=True)\n",
    "        return f_data\n",
    "\n",
    "    def update_forex_data(self, old_data_path, save_path='forex_data.feather'):\n",
    "        old_data = pd.read_feather(old_data_path)\n",
    "        old_data.set_index('timestamp', inplace=True)\n",
    "\n",
    "        forex_data = self.download_data('EUR', 'PLN')\n",
    "\n",
    "        for main in self.main_currencies:\n",
    "            for add in self.additional_currencies:\n",
    "                if main == add:\n",
    "                    continue\n",
    "                temp_data = self.download_data(main, add)\n",
    "                forex_data = forex_data.join(temp_data)\n",
    "\n",
    "        forex_data = pd.concat([forex_data, old_data])\n",
    "\n",
    "        forex_data.reset_index(inplace=True)\n",
    "        forex_data.drop_duplicates(subset=['timestamp'], inplace=True)\n",
    "        forex_data.sort_index(inplace=True)\n",
    "        \n",
    "        forex_data.to_feather(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_path = '/kaggle/input/forex-data-downloader/forex_data.feather'\n",
    "\n",
    "handler = ForexDataHandler()\n",
    "handler.update_forex_data(forex_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economic calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EconomicDataHandler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_date: str = \"2020-01-01\",\n",
    "        end_date: pd.Timestamp = pd.Timestamp.today().normalize(),\n",
    "        chunk_days: int = 30,\n",
    "        save_path: str = None\n",
    "    ):\n",
    "        self.start_date = pd.to_datetime(start_date)\n",
    "        self.end_date = end_date\n",
    "        self.chunk_delta = pd.Timedelta(days=chunk_days)\n",
    "        self.save_path = save_path\n",
    "        self.date_ranges = self._generate_date_ranges()\n",
    "        self.clean_chunks = []\n",
    "\n",
    "    def _generate_date_ranges(self):\n",
    "        # Split the full interval into successive (start, end) pairs\n",
    "        ranges = []\n",
    "        curr = self.start_date\n",
    "        \n",
    "        while curr <= self.end_date:\n",
    "            end = min(curr + self.chunk_delta, self.end_date)\n",
    "            ranges.append((curr, end))\n",
    "            curr = curr + self.chunk_delta\n",
    "\n",
    "        return ranges\n",
    "\n",
    "    def _fetch_range(self, start: pd.Timestamp, to: pd.Timestamp) -> pd.DataFrame:\n",
    "        # Download raw events JSON and convert to DataFrame.\n",
    "        url = \"https://economic-calendar.tradingview.com/events\"\n",
    "        params = {\n",
    "            \"from\": start.date().isoformat(), \n",
    "            \"to\": to.date().isoformat()\n",
    "            }\n",
    "        headers = {\"Origin\": \"https://www.tradingview.com\"}\n",
    "\n",
    "        resp = requests.get(url, headers=headers, params=params)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json().get(\"result\", [])\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def _clean_df(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        # Fill missing values in referenceDate and create new \"Timestamp\" column\n",
    "        df[\"referenceDate\"] = df[\"referenceDate\"].fillna(df[\"date\"])\n",
    "        df['referenceDate'] = pd.to_datetime(df[\"referenceDate\"], format='mixed', yearfirst=True)\n",
    "        df['timestamp'] = df['referenceDate'].apply(lambda x: x.timestamp()).astype(int)\n",
    "\n",
    "        # Drop unimportant columns, duplicates and rows without crucial data\n",
    "        calendar_drop = ['id', 'period', 'source', 'ticker', 'scale', 'category',\n",
    "                            'actualRaw', 'previousRaw', 'forecastRaw', 'source_url'\n",
    "                        ]\n",
    "        df.drop(calendar_drop, axis=1, inplace=True)\n",
    "        df.dropna(subset=['actual'], inplace=True)\n",
    "        df.drop_duplicates(subset=['title', 'date', 'indicator', 'country', 'referenceDate', 'actual'], inplace=True, keep='last')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def download(self) -> pd.DataFrame:\n",
    "        # Main entry: fetch all data, clean and save if requested\n",
    "        for start, to in tqdm(self.date_ranges, desc=\"Downloading chunks\"):\n",
    "            try:\n",
    "                raw = self._fetch_range(start, to)\n",
    "                clean = self._clean_df(raw)\n",
    "                self.clean_chunks.append(clean)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {start.date()}→{to.date()}: {e}\")\n",
    "\n",
    "        data = pd.concat(self.clean_chunks, ignore_index=True)\n",
    "        data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        if self.save_path:\n",
    "            data.to_feather(self.save_path)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3626c519d6bf4504ba73789c567cfd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading chunks:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Economic_handler = EconomicDataHandler()\n",
    "economic_data = Economic_handler.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T20:25:20.639842Z",
     "iopub.status.busy": "2024-02-10T20:25:20.639194Z",
     "iopub.status.idle": "2024-02-10T20:25:21.260039Z",
     "shell.execute_reply": "2024-02-10T20:25:21.258998Z",
     "shell.execute_reply.started": "2024-02-10T20:25:20.639796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "forex_data = pd.read_feather('/kaggle/input/forex-data-gatherer/forex_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T20:25:21.264941Z",
     "iopub.status.busy": "2024-02-10T20:25:21.264592Z",
     "iopub.status.idle": "2024-02-10T20:25:21.717665Z",
     "shell.execute_reply": "2024-02-10T20:25:21.716272Z",
     "shell.execute_reply.started": "2024-02-10T20:25:21.264909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Economic calendar d.aggregateta\n",
    "economic_df = pd.read_feather('/kaggle/input/economic-calendar-data/economic_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "economic_poland = economic_df[economic_df['country']=='PL'].copy()\n",
    "economic_poland.reset_index(inplace=True)\n",
    "economic_poland.drop('index', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T20:52:36.249431Z",
     "iopub.status.busy": "2024-02-10T20:52:36.249005Z",
     "iopub.status.idle": "2024-02-10T20:52:36.319587Z",
     "shell.execute_reply": "2024-02-10T20:52:36.318717Z",
     "shell.execute_reply.started": "2024-02-10T20:52:36.249396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# fix some data(sometimes records from previous months are saved next month as duplicates)\n",
    "economic_poland = economic_df[economic_df['country']=='PL'].copy()\n",
    "\n",
    "mask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\n",
    "for idx, [index, row] in enumerate(economic_poland.loc[mask].iterrows()):\n",
    "    try:\n",
    "        pair = economic_poland.loc[mask].iloc[idx+1]\n",
    "        if all(row[['date', 'title']] == pair[['date', 'title']]):\n",
    "            if row['actual'] == pair['previous']:\n",
    "                new_date = pd.to_datetime(row['date'])\n",
    "                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == row['title']]['date']).diff().dt.days.median()\n",
    "                new_date = new_date - pd.Timedelta(days=time_diff)\n",
    "                economic_poland.loc[[index], ['date']] = new_date.strftime('%Y-%m-%d')\n",
    "            else:\n",
    "                new_date = pd.to_datetime(pair['date'])\n",
    "                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == pair['title']]['date']).diff().dt.days.median()\n",
    "                new_date = new_date - pd.Timedelta(days=time_diff)\n",
    "                economic_poland.loc[[pair.name], ['date']] = new_date.strftime('%Y-%m-%d')\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T21:26:24.195350Z",
     "iopub.status.busy": "2024-02-10T21:26:24.194963Z",
     "iopub.status.idle": "2024-02-10T21:26:24.690134Z",
     "shell.execute_reply": "2024-02-10T21:26:24.688841Z",
     "shell.execute_reply.started": "2024-02-10T21:26:24.195317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Create new df with continues range of dates and all indicator values in any day\n",
    "\n",
    "df_pivot = economic_poland.pivot(columns='title', values='actual')\n",
    "\n",
    "#merge tables to update dates\n",
    "merged = df_pivot.merge(economic_poland, left_index=True, right_index=True)\n",
    "merged.drop(['title', 'country', 'indicator', 'comment','actual', 'previous', 'forecast', 'importance'], axis=1, inplace=True)\n",
    "merged.reset_index(inplace=True)\n",
    "\n",
    "#create continues dates from oldest to newest \n",
    "idx = pd.date_range(merged.date.min(), merged.date.max())\n",
    "idx = idx.strftime('%Y-%m-%d')\n",
    "\n",
    "#create new dataframe with full set of date range\n",
    "new_df = pd.DataFrame(index=idx, columns=merged.columns)\n",
    "new_df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# change date column to str to be merge\n",
    "merged['date'] = merged['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "#merge both dataframes table with values in full set of ranges\n",
    "fullset = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\n",
    "fullset.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "#fill all nans with values from previous rows(newest)\n",
    "fullset = fullset.ffill()\n",
    "\n",
    "#drop duplicates\n",
    "fullset.drop_duplicates(subset=['date'], inplace=True, keep='last')\n",
    "fullset.set_index('date', inplace=True)\n",
    "fullset.drop('index', inplace=True, axis=1)\n",
    "\n",
    "#fill rest of nan values(oldest data) with oldest 'previous' value from main df - check if it is not bettter to leave nan\n",
    "for col in fullset.columns:\n",
    "    if pd.isna(fullset[col].iloc[0]):\n",
    "        value = economic_poland.loc[economic_poland['title'] == col].iloc[0]['previous']\n",
    "        fullset[col] = fullset[col].fillna(value)\n",
    "        \n",
    "#check if last row in our dataframe is correct\n",
    "test_df = pd.DataFrame()\n",
    "for title in economic_poland['title'].unique():\n",
    "    test_df[title] = [economic_poland[economic_poland[\"title\"]==title].iloc[-1][\"actual\"]]\n",
    "    \n",
    "test_true = fullset.drop('timestamp', axis=1).iloc[-1] == test_df\n",
    "print(test_true.iloc[0].unique()) #it should only contain \"True\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T21:26:28.251194Z",
     "iopub.status.busy": "2024-02-10T21:26:28.250797Z",
     "iopub.status.idle": "2024-02-10T21:26:28.288763Z",
     "shell.execute_reply": "2024-02-10T21:26:28.287690Z",
     "shell.execute_reply.started": "2024-02-10T21:26:28.251167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fullset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T21:15:57.223961Z",
     "iopub.status.busy": "2024-02-10T21:15:57.223633Z",
     "iopub.status.idle": "2024-02-10T21:15:57.245432Z",
     "shell.execute_reply": "2024-02-10T21:15:57.244018Z",
     "shell.execute_reply.started": "2024-02-10T21:15:57.223934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "error = []\n",
    "for title in economic_poland.title.unique():\n",
    "    all_rows = economic_poland[economic_poland.title == title]\n",
    "    for index, [idx, row] in enumerate(all_rows.iterrows()):\n",
    "        try:\n",
    "            now = row['date']\n",
    "            until = pd.to_datetime(all_rows.iloc[index+1]['date'])\n",
    "            until = until - pd.Timedelta(days=1)\n",
    "            until = until.strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            pass\n",
    "        if now > until:\n",
    "            temp1 = now\n",
    "            now = until\n",
    "            until = temp1\n",
    "        actual = row['actual']\n",
    "        if all(actual != fullset.loc[now:until][indicator]):\n",
    "            error.append([now, until, actual, fullset.loc[now][indicator], indicator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T21:54:37.550906Z",
     "iopub.status.busy": "2023-05-28T21:54:37.550063Z",
     "iopub.status.idle": "2023-05-28T21:54:38.061824Z",
     "shell.execute_reply": "2023-05-28T21:54:38.060676Z",
     "shell.execute_reply.started": "2023-05-28T21:54:37.550852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#merge both dataframes table with values in full set of ranges\n",
    "fullset2 = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\n",
    "fullset2.dropna(axis=1, how='all', inplace=True)\n",
    "fullset2.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T22:09:16.543059Z",
     "iopub.status.busy": "2023-05-28T22:09:16.542534Z",
     "iopub.status.idle": "2023-05-28T22:09:16.555186Z",
     "shell.execute_reply": "2023-05-28T22:09:16.553738Z",
     "shell.execute_reply.started": "2023-05-28T22:09:16.543011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fullset['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T23:44:29.812726Z",
     "iopub.status.busy": "2023-05-28T23:44:29.810661Z",
     "iopub.status.idle": "2023-05-28T23:44:29.861482Z",
     "shell.execute_reply": "2023-05-28T23:44:29.860474Z",
     "shell.execute_reply.started": "2023-05-28T23:44:29.812654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\n",
    "economic_poland.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "economic_poland[economic_poland['date'] == '2016-03-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fullset2['Inflation Rate YoY Final'].dropna()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fullset2['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Forex data\n",
    "forex_df = pd.read_excel('/kaggle/input/forex-data-gatherer/FOREX_DATA.xlsx')\n",
    "\n",
    "forex_df['Datetime'] = pd.to_datetime(forex_df['Datetime'], dayfirst=True)\n",
    "forex_df = dataframe.sort_values(by='Datetime', ascending=False)\n",
    "forex_df['Datetime'] = forex_df[\"Datetime\"].dt.strftime('%d-%m-%Y %H:%M:%S %z')\n",
    "forex_df.set_index('Datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "join_df = dataframe.join(calendar_df).drop_duplicates()\n",
    "join_df = join_df[~join_df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "join_df.loc['28-03-2023 07:00:00 +0100']"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3274009,
     "sourceId": 7494554,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 252531721,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
