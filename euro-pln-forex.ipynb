{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7494554,"datasetId":3274009,"databundleVersionId":7587411},{"sourceType":"kernelVersion","sourceId":244770917}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Instalations\n!python -m pip install --upgrade pip\n#!pip install yfinance\n!pip install yfinance==0.2.59\n!pip install curl-cffi\n\n# Imports\nfrom curl_cffi import requests \nimport yfinance as yf\nimport pandas as pd\n\nprint(yf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-06-20T16:34:24.822840Z","iopub.execute_input":"2025-06-20T16:34:24.823462Z","iopub.status.idle":"2025-06-20T16:34:54.149656Z","shell.execute_reply.started":"2025-06-20T16:34:24.823434Z","shell.execute_reply":"2025-06-20T16:34:54.148840Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\nCollecting yfinance==0.2.59\n  Downloading yfinance-0.2.59-py2.py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.2.3)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.32.3)\nRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (0.0.11)\nRequirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (4.3.8)\nRequirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2025.2)\nRequirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (2.4.6)\nRequirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (3.17.9)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (4.13.3)\nCollecting curl_cffi>=0.7 (from yfinance==0.2.59)\n  Downloading curl_cffi-0.11.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nCollecting protobuf<6,>=5.29.0 (from yfinance==0.2.59)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from yfinance==0.2.59) (15.0.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.59) (4.13.2)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (1.17.1)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance==0.2.59) (2025.4.26)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance==0.2.59) (2.22)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.5->yfinance==0.2.59) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance==0.2.59) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance==0.2.59) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance==0.2.59) (2.4.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.5->yfinance==0.2.59) (2022.1.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->yfinance==0.2.59) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.5->yfinance==0.2.59) (2024.2.0)\nDownloading yfinance-0.2.59-py2.py3-none-any.whl (117 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\nDownloading curl_cffi-0.11.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, curl_cffi, yfinance\n\u001b[2K  Attempting uninstall: protobuf\n\u001b[2K    Found existing installation: protobuf 3.20.3\n\u001b[2K    Uninstalling protobuf-3.20.3:\n\u001b[2K      Successfully uninstalled protobuf-3.20.3━━\u001b[0m \u001b[32m0/3\u001b[0m [protobuf]\n\u001b[2K  Attempting uninstall: yfinance[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [curl_cffi]\n\u001b[2K    Found existing installation: yfinance 0.2.55━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [curl_cffi]\n\u001b[2K    Uninstalling yfinance-0.2.55:90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [curl_cffi]\n\u001b[2K      Successfully uninstalled yfinance-0.2.55━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [curl_cffi]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [yfinance]2/3\u001b[0m [yfinance]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed curl_cffi-0.11.4 protobuf-5.29.5 yfinance-0.2.59\nRequirement already satisfied: curl-cffi in /usr/local/lib/python3.11/dist-packages (0.11.4)\nRequirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl-cffi) (1.17.1)\nRequirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl-cffi) (2025.4.26)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl-cffi) (2.22)\n0.2.59\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Forex data","metadata":{}},{"cell_type":"code","source":"#FUNCTIONS\n\ndef download_data(cur_1, cur_2, t_period='5d', t_interval='1m'):\n\n    session = requests.Session(impersonate=\"chrome\", timeout=5)\n    #DOWNLOAD DATA\n    data = yf.Ticker(f'{cur_1}{cur_2}=X', session=session)\n    f_data = data.history(period=t_period, interval=t_interval)\n    #REMOVE TABLES WITH 0\n    mask = f_data.ne(0).any(axis=0)\n    f_data = f_data.loc[:, mask]\n    \n    f_data.reset_index(inplace=True)\n    #RENAME COLUMNS\n    f_data.rename(columns={'Datetime': 'timestamp', 'Open':f'{cur_1}{cur_2}_OPEN', 'High':f'{cur_1}{cur_2}_HIGH', \n                         'Low':f'{cur_1}{cur_2}_LOW', 'Close':f'{cur_1}{cur_2}_CLOSE'}, inplace=True)\n    \n    f_data['timestamp'] = f_data['timestamp'].apply(lambda x: x.timestamp()).astype(int)\n    f_data.set_index('timestamp', inplace=True)\n    return f_data\n\n#Download new forex data and merge it with old one\ndef update_forex_data(old_data_path):\n    #LOAD OLD DATA GMT +1\n    old_data = pd.read_feather(old_data_path)\n    old_data.set_index('timestamp', inplace=True)\n\n    #CURRENCIES PAIRS WHICH WE WANT DOWNLOAD\n    main_cur = ['PLN', 'EUR']\n    additional_cur = ['CZK', 'HUF', 'USD', 'CHF', 'GBP', 'JPY']\n\n    #DOWNLOAD OUR MAIN CURRENCY PAIR\n    forex_data = download_data('EUR', 'PLN')\n\n    #DOWNLOAD OUR ADDITIONAL CURRENCY PAIRS\n    for main in main_cur:\n        for add in additional_cur:\n            #DOWNLOAD PAIR DATA\n            temp_data = download_data(main, add)\n            #JOIN TO MAIN TABLE\n            forex_data = forex_data.join(temp_data)\n\n    #JOIN OLD AND NEW DATA(FROM THIS WEEK)\n    forex_data = pd.concat([forex_data, old_data])\n\n    #remove duplicates and sort values\n    forex_data.sort_index(inplace=True)\n    forex_data.reset_index(inplace=True)\n    forex_data.drop_duplicates(['timestamp'], inplace=True)\n    forex_data.reset_index(inplace=True)\n    forex_data.drop('index', axis=1, inplace=True)\n    \n    #SAVE TO feather\n    forex_data.to_feather('forex_data.feather')\n    \n#Download daily forex data - DEPRECIATED use \"download_data\"\ndef daily_forex_data(pair=\"EUR/PLN\", interval=\"1day\", size=\"5000\"):\n    url = \"https://twelve-data1.p.rapidapi.com/time_series\"\n    querystring = {\"symbol\":pair,\"interval\":interval,\"outputsize\":size,\"format\":\"json\"}\n\n    headers = {\n        \"X-RapidAPI-Key\": \"863b6e82d7msha3b96a4e153c426p11a206jsn073ad98d5070\",\n        \"X-RapidAPI-Host\": \"twelve-data1.p.rapidapi.com\"\n    }\n\n    response = requests.get(url, headers=headers, params=querystring).json()\n    return pd.DataFrame(response['values'])    ","metadata":{"execution":{"iopub.status.busy":"2025-06-20T16:34:54.151183Z","iopub.execute_input":"2025-06-20T16:34:54.151762Z","iopub.status.idle":"2025-06-20T16:34:54.163398Z","shell.execute_reply.started":"2025-06-20T16:34:54.151724Z","shell.execute_reply":"2025-06-20T16:34:54.162172Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import yfinance as yf\nimport pandas as pd\nimport requests\n\n\nclass ForexDataHandler:\n    def __init__(self, main_currencies=None, additional_currencies=None):\n        self.main_currencies = main_currencies or ['PLN', 'EUR']\n        self.additional_currencies = additional_currencies or ['CZK', 'HUF', 'USD', 'CHF', 'GBP', 'JPY']\n\n    def download_data(self, cur_1, cur_2, t_period='5d', t_interval='1m'):\n        symbol = f'{cur_1}{cur_2}=X'\n        data = yf.Ticker(symbol)\n        f_data = data.history(period=t_period, interval=t_interval)\n\n        mask = f_data.ne(0).any(axis=0)\n        f_data = f_data.loc[:, mask]\n\n        f_data.reset_index(inplace=True)\n        f_data.rename(columns={\n            'Datetime': 'timestamp',\n            'Open': f'{cur_1}{cur_2}_OPEN',\n            'High': f'{cur_1}{cur_2}_HIGH',\n            'Low': f'{cur_1}{cur_2}_LOW',\n            'Close': f'{cur_1}{cur_2}_CLOSE'\n        }, inplace=True)\n\n        f_data['timestamp'] = f_data['timestamp'].apply(lambda x: x.timestamp()).astype(int)\n        f_data.set_index('timestamp', inplace=True)\n        return f_data\n\n    def update_forex_data(self, old_data_path, save_path='forex_data.feather'):\n        old_data = pd.read_feather(old_data_path)\n        old_data.set_index('timestamp', inplace=True)\n\n        forex_data = self.download_data('EUR', 'PLN')\n\n        for main in self.main_currencies:\n            for add in self.additional_currencies:\n                if main == add:\n                    continue\n                temp_data = self.download_data(main, add)\n                forex_data = forex_data.join(temp_data)\n\n        forex_data = pd.concat([forex_data, old_data])\n        forex_data.sort_index(inplace=True)\n        forex_data.reset_index(inplace=True)\n        forex_data.drop_duplicates(subset=['timestamp'], inplace=True)\n        forex_data.to_feather(save_path)\n\n    def download_daily_forex_data(self, pair=\"EUR/PLN\", interval=\"1day\", size=\"5000\"):\n        url = \"https://twelve-data1.p.rapidapi.com/time_series\"\n        querystring = {\"symbol\": pair, \"interval\": interval, \"outputsize\": size, \"format\": \"json\"}\n        headers = {\n            \"X-RapidAPI-Key\": \"your_api_key\",\n            \"X-RapidAPI-Host\": \"twelve-data1.p.rapidapi.com\"\n        }\n        response = requests.get(url, headers=headers, params=querystring).json()\n        return pd.DataFrame(response['values'])\n\n# Example usage:\n# handler = ForexDataHandler()\n# handler.update_forex_data('old_forex_data.feather')\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Update forex data\nforex_path = '/kaggle/input/forex-data-gatherer/forex_data.feather'\nupdate_forex_data(forex_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:34:54.164602Z","iopub.execute_input":"2025-06-20T16:34:54.165413Z","iopub.status.idle":"2025-06-20T16:35:02.211103Z","shell.execute_reply.started":"2025-06-20T16:34:54.165386Z","shell.execute_reply":"2025-06-20T16:35:02.209853Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Daily forex data\ndaily_forex = download_data('EUR', 'PLN', '5000d', '1d')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Economic calendar data","metadata":{}},{"cell_type":"code","source":"#import\nimport pandas as pd\nimport numpy as np\nimport requests","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:25:20.631698Z","iopub.execute_input":"2024-02-10T20:25:20.633471Z","iopub.status.idle":"2024-02-10T20:25:20.637835Z","shell.execute_reply.started":"2024-02-10T20:25:20.633438Z","shell.execute_reply":"2024-02-10T20:25:20.636990Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create dates pairs for economic calendar(calendar max offset is 30 days)\ndates_pairs = []\ninitial_date = \"2010-01-01\"\nend_date_init = pd.Timestamp.today().normalize()\nstart_date = pd.to_datetime(initial_date)\n\nwhile start_date <= end_date_init:\n    end_date = (start_date + pd.offsets.Day(30))\n    dates_pairs.append((start_date.date().isoformat(), end_date.date().isoformat()))\n    start_date = end_date","metadata":{"execution":{"iopub.status.busy":"2024-01-31T20:52:15.858654Z","iopub.execute_input":"2024-01-31T20:52:15.859320Z","iopub.status.idle":"2024-01-31T20:52:15.877292Z","shell.execute_reply.started":"2024-01-31T20:52:15.859258Z","shell.execute_reply":"2024-01-31T20:52:15.875958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create and save economic calendar with all possible fetched data\ndf_list = []\nfor pair in dates_pairs:\n    try:\n        url = 'https://economic-calendar.tradingview.com/events'\n        payload = {\n            'from': pair[0],\n            'to': pair[1]\n        }\n        data = requests.get(url, params=payload).json()\n        calendar_df = pd.DataFrame(data['result'])\n\n        #Drop unimportant columns and rows\n        calendar_drop = ['id', 'period', 'source', 'currency', 'ticker', 'unit', 'scale']\n        calendar_df.drop(calendar_drop, axis=1, inplace=True)\n        calendar_df.dropna(subset=['actual'], inplace=True)\n\n        #Sort and convert time to GMT +1\n        calendar_df['date'] = pd.to_datetime(calendar_df['date'], dayfirst=True).dt.tz_convert('Europe/London')\n        calendar_df['timestamp'] = calendar_df['date'].apply(lambda x: x.timestamp()).astype(int)\n        calendar_df.set_index('timestamp', inplace=True)\n        calendar_df.sort_index(inplace=True)\n        df_list.append(calendar_df)\n    except Exception as e:\n        pass\n    \neconomic_data = pd.concat(df_list)\neconomic_data.reset_index(inplace=True)\neconomic_data.to_feather(\"economic_data.feather\")    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"forex_data = pd.read_feather('/kaggle/input/forex-data-gatherer/forex_data.feather')","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:25:20.639194Z","iopub.execute_input":"2024-02-10T20:25:20.639842Z","iopub.status.idle":"2024-02-10T20:25:21.260039Z","shell.execute_reply.started":"2024-02-10T20:25:20.639796Z","shell.execute_reply":"2024-02-10T20:25:21.258998Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Economic calendar d.aggregateta\neconomic_df = pd.read_feather('/kaggle/input/economic-calendar-data/economic_data.feather')","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:25:21.264592Z","iopub.execute_input":"2024-02-10T20:25:21.264941Z","iopub.status.idle":"2024-02-10T20:25:21.717665Z","shell.execute_reply.started":"2024-02-10T20:25:21.264909Z","shell.execute_reply":"2024-02-10T20:25:21.716272Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"economic_poland = economic_df[economic_df['country']=='PL'].copy()\neconomic_poland.reset_index(inplace=True)\neconomic_poland.drop('index', inplace=True, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fix some data(sometimes records from previous months are saved next month as duplicates)\neconomic_poland = economic_df[economic_df['country']=='PL'].copy()\n\nmask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\nfor idx, [index, row] in enumerate(economic_poland.loc[mask].iterrows()):\n    try:\n        pair = economic_poland.loc[mask].iloc[idx+1]\n        if all(row[['date', 'title']] == pair[['date', 'title']]):\n            if row['actual'] == pair['previous']:\n                new_date = pd.to_datetime(row['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == row['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[index], ['date']] = new_date.strftime('%Y-%m-%d')\n            else:\n                new_date = pd.to_datetime(pair['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == pair['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[pair.name], ['date']] = new_date.strftime('%Y-%m-%d')\n    except Exception as e:\n        continue\n        #print(e)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:52:36.249005Z","iopub.execute_input":"2024-02-10T20:52:36.249431Z","iopub.status.idle":"2024-02-10T20:52:36.319587Z","shell.execute_reply.started":"2024-02-10T20:52:36.249396Z","shell.execute_reply":"2024-02-10T20:52:36.318717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create new df with continues range of dates and all indicator values in any day\n\ndf_pivot = economic_poland.pivot(columns='title', values='actual')\n\n#merge tables to update dates\nmerged = df_pivot.merge(economic_poland, left_index=True, right_index=True)\nmerged.drop(['title', 'country', 'indicator', 'comment','actual', 'previous', 'forecast', 'importance'], axis=1, inplace=True)\nmerged.reset_index(inplace=True)\n\n#create continues dates from oldest to newest \nidx = pd.date_range(merged.date.min(), merged.date.max())\nidx = idx.strftime('%Y-%m-%d')\n\n#create new dataframe with full set of date range\nnew_df = pd.DataFrame(index=idx, columns=merged.columns)\nnew_df.drop('date', axis=1, inplace=True)\n\n# change date column to str to be merge\nmerged['date'] = merged['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n\n#merge both dataframes table with values in full set of ranges\nfullset = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset.dropna(axis=1, how='all', inplace=True)\n\n#fill all nans with values from previous rows(newest)\nfullset = fullset.ffill()\n\n#drop duplicates\nfullset.drop_duplicates(subset=['date'], inplace=True, keep='last')\nfullset.set_index('date', inplace=True)\nfullset.drop('index', inplace=True, axis=1)\n\n#fill rest of nan values(oldest data) with oldest 'previous' value from main df - check if it is not bettter to leave nan\nfor col in fullset.columns:\n    if pd.isna(fullset[col].iloc[0]):\n        value = economic_poland.loc[economic_poland['title'] == col].iloc[0]['previous']\n        fullset[col] = fullset[col].fillna(value)\n        \n#check if last row in our dataframe is correct\ntest_df = pd.DataFrame()\nfor title in economic_poland['title'].unique():\n    test_df[title] = [economic_poland[economic_poland[\"title\"]==title].iloc[-1][\"actual\"]]\n    \ntest_true = fullset.drop('timestamp', axis=1).iloc[-1] == test_df\nprint(test_true.iloc[0].unique()) #it should only contain \"True\" values","metadata":{"execution":{"iopub.status.busy":"2024-02-10T21:26:24.194963Z","iopub.execute_input":"2024-02-10T21:26:24.195350Z","iopub.status.idle":"2024-02-10T21:26:24.690134Z","shell.execute_reply.started":"2024-02-10T21:26:24.195317Z","shell.execute_reply":"2024-02-10T21:26:24.688841Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset","metadata":{"execution":{"iopub.status.busy":"2024-02-10T21:26:28.250797Z","iopub.execute_input":"2024-02-10T21:26:28.251194Z","iopub.status.idle":"2024-02-10T21:26:28.288763Z","shell.execute_reply.started":"2024-02-10T21:26:28.251167Z","shell.execute_reply":"2024-02-10T21:26:28.287690Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"error = []\nfor title in economic_poland.title.unique():\n    all_rows = economic_poland[economic_poland.title == title]\n    for index, [idx, row] in enumerate(all_rows.iterrows()):\n        try:\n            now = row['date']\n            until = pd.to_datetime(all_rows.iloc[index+1]['date'])\n            until = until - pd.Timedelta(days=1)\n            until = until.strftime('%Y-%m-%d')\n        except:\n            pass\n        if now > until:\n            temp1 = now\n            now = until\n            until = temp1\n        actual = row['actual']\n        if all(actual != fullset.loc[now:until][indicator]):\n            error.append([now, until, actual, fullset.loc[now][indicator], indicator])","metadata":{"execution":{"iopub.status.busy":"2024-02-10T21:15:57.223633Z","iopub.execute_input":"2024-02-10T21:15:57.223961Z","iopub.status.idle":"2024-02-10T21:15:57.245432Z","shell.execute_reply.started":"2024-02-10T21:15:57.223934Z","shell.execute_reply":"2024-02-10T21:15:57.244018Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#merge both dataframes table with values in full set of ranges\nfullset2 = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset2.dropna(axis=1, how='all', inplace=True)\nfullset2.set_index('date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:54:37.550063Z","iopub.execute_input":"2023-05-28T21:54:37.550906Z","iopub.status.idle":"2023-05-28T21:54:38.061824Z","shell.execute_reply.started":"2023-05-28T21:54:37.550852Z","shell.execute_reply":"2023-05-28T21:54:38.060676Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:09:16.542534Z","iopub.execute_input":"2023-05-28T22:09:16.543059Z","iopub.status.idle":"2023-05-28T22:09:16.555186Z","shell.execute_reply.started":"2023-05-28T22:09:16.543011Z","shell.execute_reply":"2023-05-28T22:09:16.553738Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\neconomic_poland.loc[mask]","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:44:29.810661Z","iopub.execute_input":"2023-05-28T23:44:29.812726Z","iopub.status.idle":"2023-05-28T23:44:29.861482Z","shell.execute_reply.started":"2023-05-28T23:44:29.812654Z","shell.execute_reply":"2023-05-28T23:44:29.860474Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"economic_poland[economic_poland['date'] == '2016-03-15']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final'].dropna()[0:20]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Forex data\nforex_df = pd.read_excel('/kaggle/input/forex-data-gatherer/FOREX_DATA.xlsx')\n\nforex_df['Datetime'] = pd.to_datetime(forex_df['Datetime'], dayfirst=True)\nforex_df = dataframe.sort_values(by='Datetime', ascending=False)\nforex_df['Datetime'] = forex_df[\"Datetime\"].dt.strftime('%d-%m-%Y %H:%M:%S %z')\nforex_df.set_index('Datetime', inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_df = dataframe.join(calendar_df).drop_duplicates()\njoin_df = join_df[~join_df.index.duplicated(keep='first')]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"join_df.loc['28-03-2023 07:00:00 +0100']","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}