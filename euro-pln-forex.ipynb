{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7494554,"sourceType":"datasetVersion","datasetId":3274009},{"sourceId":195348436,"sourceType":"kernelVersion"}],"dockerImageVersionId":30445,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import/instalations\n!pip install yfinance\nimport yfinance as yf\nimport pandas as pd\nimport requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-23T19:11:49.290977Z","iopub.execute_input":"2024-09-23T19:11:49.291963Z","iopub.status.idle":"2024-09-23T19:12:18.525700Z","shell.execute_reply.started":"2024-09-23T19:11:49.291898Z","shell.execute_reply":"2024-09-23T19:12:18.523981Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting yfinance\n  Downloading yfinance-0.2.43-py2.py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.7/site-packages (from yfinance) (4.9.2)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.7/site-packages (from yfinance) (4.11.1)\nRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.3.5)\nCollecting requests>=2.31\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.1)\nCollecting multitasking>=0.0.7\n  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\nCollecting peewee>=3.16.2\n  Downloading peewee-3.17.6.tar.gz (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: platformdirs>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from yfinance) (2.6.2)\nRequirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.7/site-packages (from yfinance) (2022.7.1)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from yfinance) (1.21.6)\nRequirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.7/site-packages (from yfinance) (2.3.6)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.2.post1)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\nRequirement already satisfied: typing-extensions>=4.4 in /opt/conda/lib/python3.7/site-packages (from platformdirs>=2.0.0->yfinance) (4.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.31->yfinance) (2.1.1)\nBuilding wheels for collected packages: peewee\n  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.6-py3-none-any.whl size=138888 sha256=507fdeb1732f7d3c7b0581ecbc0fe6c11b267b010269e336e53b5c7c653bfdb8\n  Stored in directory: /root/.cache/pip/wheels/12/56/4d/e4422b18d363b7e6b3c258662a21382a839f02306fb4b92ffc\nSuccessfully built peewee\nInstalling collected packages: peewee, multitasking, requests, yfinance\n  Attempting uninstall: requests\n    Found existing installation: requests 2.28.2\n    Uninstalling requests-2.28.2:\n      Successfully uninstalled requests-2.28.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npandas-profiling 3.6.2 requires requests<2.29,>=2.24.0, but you have requests 2.31.0 which is incompatible.\nlibrosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed multitasking-0.0.11 peewee-3.17.6 requests-2.31.0 yfinance-0.2.43\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Forex data","metadata":{}},{"cell_type":"code","source":"#FUNCTIONS\n\n#Download forex data for 1 pair from last 7 days in 1 minute intervals \ndef download_data(cur_1, cur_2, t_period='5d', t_interval='1m'):\n    #DOWNLOAD DATA\n    data = yf.Ticker(f'{cur_1}{cur_2}=X')\n    f_data = data.history(period=t_period, interval=t_interval)\n    #REMOVE TABLES WITH 0\n    mask = f_data.ne(0).any(axis=0)\n    f_data = f_data.loc[:, mask]\n    \n    f_data.reset_index(inplace=True)\n    #RENAME COLUMNS\n    f_data.rename(columns={'Datetime': 'timestamp', 'Open':f'{cur_1}{cur_2}_OPEN', 'High':f'{cur_1}{cur_2}_HIGH', \n                         'Low':f'{cur_1}{cur_2}_LOW', 'Close':f'{cur_1}{cur_2}_CLOSE'}, inplace=True)\n    \n    \n    f_data['timestamp'] = f_data['timestamp'].apply(lambda x: x.timestamp()).astype(int)\n    f_data.set_index('timestamp', inplace=True)\n    return f_data\n\n#Download new forex data and merge it with old one\ndef update_forex_data(old_data_path):\n    #LOAD OLD DATA GMT +1\n    old_data = pd.read_feather(old_data_path)\n    old_data.set_index('timestamp', inplace=True)\n\n    #CURRENCIES PAIRS WHICH WE WANT DOWNLOAD\n    main_cur = ['PLN', 'EUR']\n    additional_cur = ['CZK', 'HUF', 'USD', 'CHF', 'GBP', 'JPY']\n\n    #DOWNLOAD OUR MAIN CURRENCY PAIR\n    forex_data = download_data('EUR', 'PLN')\n\n    #DOWNLOAD OUR ADDITIONAL CURRENCY PAIRS\n    for main in main_cur:\n        for add in additional_cur:\n            #DOWNLOAD PAIR DATA\n            temp_data = download_data(main, add)\n            #JOIN TO MAIN TABLE\n            forex_data = forex_data.join(temp_data)\n\n    #JOIN OLD AND NEW DATA(FROM THIS WEEK)\n    forex_data = pd.concat([forex_data, old_data])\n\n    #remove duplicates and sort values\n    forex_data.sort_index(inplace=True)\n    forex_data.reset_index(inplace=True)\n    forex_data.drop_duplicates(['timestamp'], inplace=True)\n    forex_data.reset_index(inplace=True)\n    forex_data.drop('index', axis=1, inplace=True)\n    \n    #SAVE TO feather\n    forex_data.to_feather('forex_data.feather')\n    \n#Download daily forex data - DEPRECIATED use \"download_data\"\ndef daily_forex_data(pair=\"EUR/PLN\", interval=\"1day\", size=\"5000\"):\n    url = \"https://twelve-data1.p.rapidapi.com/time_series\"\n    querystring = {\"symbol\":pair,\"interval\":interval,\"outputsize\":size,\"format\":\"json\"}\n\n    headers = {\n        \"X-RapidAPI-Key\": \"863b6e82d7msha3b96a4e153c426p11a206jsn073ad98d5070\",\n        \"X-RapidAPI-Host\": \"twelve-data1.p.rapidapi.com\"\n    }\n\n    response = requests.get(url, headers=headers, params=querystring).json()\n    return pd.DataFrame(response['values'])    ","metadata":{"execution":{"iopub.status.busy":"2024-09-23T19:12:18.528956Z","iopub.execute_input":"2024-09-23T19:12:18.529872Z","iopub.status.idle":"2024-09-23T19:12:18.549657Z","shell.execute_reply.started":"2024-09-23T19:12:18.529803Z","shell.execute_reply":"2024-09-23T19:12:18.548351Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Update forex data\nforex_path = '/kaggle/input/forex-data-gatherer/forex_data.feather'\nupdate_forex_data(forex_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T19:12:18.551586Z","iopub.execute_input":"2024-09-23T19:12:18.552142Z","iopub.status.idle":"2024-09-23T19:12:33.837009Z","shell.execute_reply.started":"2024-09-23T19:12:18.552068Z","shell.execute_reply":"2024-09-23T19:12:33.835804Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Daily forex data\ndaily_forex = download_data('EUR', 'PLN', '5000d', '1d')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Economic calendar data","metadata":{}},{"cell_type":"code","source":"#import\nimport pandas as pd\nimport numpy as np\nimport requests","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:25:20.631698Z","iopub.execute_input":"2024-02-10T20:25:20.633471Z","iopub.status.idle":"2024-02-10T20:25:20.637835Z","shell.execute_reply.started":"2024-02-10T20:25:20.633438Z","shell.execute_reply":"2024-02-10T20:25:20.636990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create dates pairs for economic calendar(calendar max offset is 30 days)\ndates_pairs = []\ninitial_date = \"2010-01-01\"\nend_date_init = pd.Timestamp.today().normalize()\nstart_date = pd.to_datetime(initial_date)\n\nwhile start_date <= end_date_init:\n    end_date = (start_date + pd.offsets.Day(30))\n    dates_pairs.append((start_date.date().isoformat(), end_date.date().isoformat()))\n    start_date = end_date","metadata":{"execution":{"iopub.status.busy":"2024-01-31T20:52:15.858654Z","iopub.execute_input":"2024-01-31T20:52:15.859320Z","iopub.status.idle":"2024-01-31T20:52:15.877292Z","shell.execute_reply.started":"2024-01-31T20:52:15.859258Z","shell.execute_reply":"2024-01-31T20:52:15.875958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create and save economic calendar with all possible fetched data\ndf_list = []\nfor pair in dates_pairs:\n    try:\n        url = 'https://economic-calendar.tradingview.com/events'\n        payload = {\n            'from': pair[0],\n            'to': pair[1]\n        }\n        data = requests.get(url, params=payload).json()\n        calendar_df = pd.DataFrame(data['result'])\n\n        #Drop unimportant columns and rows\n        calendar_drop = ['id', 'period', 'source', 'currency', 'ticker', 'unit', 'scale']\n        calendar_df.drop(calendar_drop, axis=1, inplace=True)\n        calendar_df.dropna(subset=['actual'], inplace=True)\n\n        #Sort and convert time to GMT +1\n        calendar_df['date'] = pd.to_datetime(calendar_df['date'], dayfirst=True).dt.tz_convert('Europe/London')\n        calendar_df['timestamp'] = calendar_df['date'].apply(lambda x: x.timestamp()).astype(int)\n        calendar_df.set_index('timestamp', inplace=True)\n        calendar_df.sort_index(inplace=True)\n        df_list.append(calendar_df)\n    except Exception as e:\n        pass\n    \neconomic_data = pd.concat(df_list)\neconomic_data.reset_index(inplace=True)\neconomic_data.to_feather(\"economic_data.feather\")    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"forex_data = pd.read_feather('/kaggle/input/forex-data-gatherer/forex_data.feather')","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:25:20.639194Z","iopub.execute_input":"2024-02-10T20:25:20.639842Z","iopub.status.idle":"2024-02-10T20:25:21.260039Z","shell.execute_reply.started":"2024-02-10T20:25:20.639796Z","shell.execute_reply":"2024-02-10T20:25:21.258998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Economic calendar d.aggregateta\neconomic_df = pd.read_feather('/kaggle/input/economic-calendar-data/economic_data.feather')","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:25:21.264592Z","iopub.execute_input":"2024-02-10T20:25:21.264941Z","iopub.status.idle":"2024-02-10T20:25:21.717665Z","shell.execute_reply.started":"2024-02-10T20:25:21.264909Z","shell.execute_reply":"2024-02-10T20:25:21.716272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"economic_poland = economic_df[economic_df['country']=='PL'].copy()\neconomic_poland.reset_index(inplace=True)\neconomic_poland.drop('index', inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix some data(sometimes records from previous months are saved next month as duplicates)\neconomic_poland = economic_df[economic_df['country']=='PL'].copy()\n\nmask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\nfor idx, [index, row] in enumerate(economic_poland.loc[mask].iterrows()):\n    try:\n        pair = economic_poland.loc[mask].iloc[idx+1]\n        if all(row[['date', 'title']] == pair[['date', 'title']]):\n            if row['actual'] == pair['previous']:\n                new_date = pd.to_datetime(row['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == row['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[index], ['date']] = new_date.strftime('%Y-%m-%d')\n            else:\n                new_date = pd.to_datetime(pair['date'])\n                time_diff = pd.to_datetime(economic_poland[economic_poland['title'] == pair['title']]['date']).diff().dt.days.median()\n                new_date = new_date - pd.Timedelta(days=time_diff)\n                economic_poland.loc[[pair.name], ['date']] = new_date.strftime('%Y-%m-%d')\n    except Exception as e:\n        continue\n        #print(e)","metadata":{"execution":{"iopub.status.busy":"2024-02-10T20:52:36.249005Z","iopub.execute_input":"2024-02-10T20:52:36.249431Z","iopub.status.idle":"2024-02-10T20:52:36.319587Z","shell.execute_reply.started":"2024-02-10T20:52:36.249396Z","shell.execute_reply":"2024-02-10T20:52:36.318717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create new df with continues range of dates and all indicator values in any day\n\ndf_pivot = economic_poland.pivot(columns='title', values='actual')\n\n#merge tables to update dates\nmerged = df_pivot.merge(economic_poland, left_index=True, right_index=True)\nmerged.drop(['title', 'country', 'indicator', 'comment','actual', 'previous', 'forecast', 'importance'], axis=1, inplace=True)\nmerged.reset_index(inplace=True)\n\n#create continues dates from oldest to newest \nidx = pd.date_range(merged.date.min(), merged.date.max())\nidx = idx.strftime('%Y-%m-%d')\n\n#create new dataframe with full set of date range\nnew_df = pd.DataFrame(index=idx, columns=merged.columns)\nnew_df.drop('date', axis=1, inplace=True)\n\n# change date column to str to be merge\nmerged['date'] = merged['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n\n#merge both dataframes table with values in full set of ranges\nfullset = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset.dropna(axis=1, how='all', inplace=True)\n\n#fill all nans with values from previous rows(newest)\nfullset = fullset.ffill()\n\n#drop duplicates\nfullset.drop_duplicates(subset=['date'], inplace=True, keep='last')\nfullset.set_index('date', inplace=True)\nfullset.drop('index', inplace=True, axis=1)\n\n#fill rest of nan values(oldest data) with oldest 'previous' value from main df - check if it is not bettter to leave nan\nfor col in fullset.columns:\n    if pd.isna(fullset[col].iloc[0]):\n        value = economic_poland.loc[economic_poland['title'] == col].iloc[0]['previous']\n        fullset[col] = fullset[col].fillna(value)\n        \n#check if last row in our dataframe is correct\ntest_df = pd.DataFrame()\nfor title in economic_poland['title'].unique():\n    test_df[title] = [economic_poland[economic_poland[\"title\"]==title].iloc[-1][\"actual\"]]\n    \ntest_true = fullset.drop('timestamp', axis=1).iloc[-1] == test_df\nprint(test_true.iloc[0].unique()) #it should only contain \"True\" values","metadata":{"execution":{"iopub.status.busy":"2024-02-10T21:26:24.194963Z","iopub.execute_input":"2024-02-10T21:26:24.195350Z","iopub.status.idle":"2024-02-10T21:26:24.690134Z","shell.execute_reply.started":"2024-02-10T21:26:24.195317Z","shell.execute_reply":"2024-02-10T21:26:24.688841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fullset","metadata":{"execution":{"iopub.status.busy":"2024-02-10T21:26:28.250797Z","iopub.execute_input":"2024-02-10T21:26:28.251194Z","iopub.status.idle":"2024-02-10T21:26:28.288763Z","shell.execute_reply.started":"2024-02-10T21:26:28.251167Z","shell.execute_reply":"2024-02-10T21:26:28.287690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = []\nfor title in economic_poland.title.unique():\n    all_rows = economic_poland[economic_poland.title == title]\n    for index, [idx, row] in enumerate(all_rows.iterrows()):\n        try:\n            now = row['date']\n            until = pd.to_datetime(all_rows.iloc[index+1]['date'])\n            until = until - pd.Timedelta(days=1)\n            until = until.strftime('%Y-%m-%d')\n        except:\n            pass\n        if now > until:\n            temp1 = now\n            now = until\n            until = temp1\n        actual = row['actual']\n        if all(actual != fullset.loc[now:until][indicator]):\n            error.append([now, until, actual, fullset.loc[now][indicator], indicator])","metadata":{"execution":{"iopub.status.busy":"2024-02-10T21:15:57.223633Z","iopub.execute_input":"2024-02-10T21:15:57.223961Z","iopub.status.idle":"2024-02-10T21:15:57.245432Z","shell.execute_reply.started":"2024-02-10T21:15:57.223934Z","shell.execute_reply":"2024-02-10T21:15:57.244018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge both dataframes table with values in full set of ranges\nfullset2 = pd.merge(new_df, merged, how='left', right_on='date', left_index=True, suffixes=(\"_x\", None))\nfullset2.dropna(axis=1, how='all', inplace=True)\nfullset2.set_index('date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-28T21:54:37.550063Z","iopub.execute_input":"2023-05-28T21:54:37.550906Z","iopub.status.idle":"2023-05-28T21:54:38.061824Z","shell.execute_reply.started":"2023-05-28T21:54:37.550852Z","shell.execute_reply":"2023-05-28T21:54:38.060676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fullset['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"execution":{"iopub.status.busy":"2023-05-28T22:09:16.542534Z","iopub.execute_input":"2023-05-28T22:09:16.543059Z","iopub.status.idle":"2023-05-28T22:09:16.555186Z","shell.execute_reply.started":"2023-05-28T22:09:16.543011Z","shell.execute_reply":"2023-05-28T22:09:16.553738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = economic_poland.duplicated(subset=['date', 'title'], keep=False)\neconomic_poland.loc[mask]","metadata":{"execution":{"iopub.status.busy":"2023-05-28T23:44:29.810661Z","iopub.execute_input":"2023-05-28T23:44:29.812726Z","iopub.status.idle":"2023-05-28T23:44:29.861482Z","shell.execute_reply.started":"2023-05-28T23:44:29.812654Z","shell.execute_reply":"2023-05-28T23:44:29.860474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"economic_poland[economic_poland['date'] == '2016-03-15']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final'].dropna()[0:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fullset2['Inflation Rate YoY Final']['2016-03-01':'2016-03-30']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Forex data\nforex_df = pd.read_excel('/kaggle/input/forex-data-gatherer/FOREX_DATA.xlsx')\n\nforex_df['Datetime'] = pd.to_datetime(forex_df['Datetime'], dayfirst=True)\nforex_df = dataframe.sort_values(by='Datetime', ascending=False)\nforex_df['Datetime'] = forex_df[\"Datetime\"].dt.strftime('%d-%m-%Y %H:%M:%S %z')\nforex_df.set_index('Datetime', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"join_df = dataframe.join(calendar_df).drop_duplicates()\njoin_df = join_df[~join_df.index.duplicated(keep='first')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"join_df.loc['28-03-2023 07:00:00 +0100']","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}