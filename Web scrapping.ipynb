{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#modules installation\n!pip install --upgrade pip\n!apt-get update -y \n!pip install selenium \n!pip install yfinance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#install google chrome \n!wget https://dl.google.com/linux/linux_signing_key.pub\n!sudo apt-key add linux_signing_key.pub\n!echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' >> /etc/apt/sources.list.d/google-chrome.list\n!sudo apt-get -y update\n!sudo apt-get install -y google-chrome-stable\n\n#install chromedrive\n!wget -O /tmp/chromedriver.zip http://chromedriver.storage.googleapis.com/`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`/chromedriver_linux64.zip\n!unzip /tmp/chromedriver.zip chromedriver -d /usr/local/bin/\n\n#check versions\n!google-chrome --version\n!chromedriver -v","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imports\nfrom selenium.webdriver.support.ui import Select\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup as bs\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport datetime\nimport re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chrome configuration\nchrome_options = webdriver.ChromeOptions()\nchrome_options.add_argument('--no-sandbox')\nchrome_options.add_argument('--headless')\nchrome_options.add_argument('--disable-gpu')\nchrome_options.add_argument('--disable-dev-shm-usage')\nchrome_options.add_argument(\"--window-size=1920,1080\")\nwd = webdriver.Chrome('chromedriver', options=chrome_options)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scraping Data from website(licenses)\nurls = {'comm': 'https://tldrlegal.com/search?reverse=true&can%5B%5D=52c0d009a1ddc9766c00000a',\n        'noncom': 'https://tldrlegal.com/search?reverse=true&cannot%5B%5D=52c0d009a1ddc9766c00000a'}\n\ndf = pd.DataFrame()\n\nall_licenses_links = {}\n\nfor url in urls:\n    wd.get(urls[url])\n    html = wd.page_source\n    soup = bs(html)\n    link_html = soup.find_all(class_='search-result flatbox')\n\n    for link in link_html:\n        temp_df = pd.DataFrame()\n        name = link.findChild(\"h3\").text\n        \n        for i in link.findChildren(\"span\"):\n            if ' can ' in str(i):\n                temp_df[i.text] = [1]\n            elif ' cannot ' in str(i):\n                temp_df[i.text] = [0]\n                \n        temp_df['Name'] = [name]    \n        df = pd.concat([df, temp_df])\n        \n        html = 'https://tldrlegal.com' + str(link.findChild(\"a\")['href'])\n        all_licenses_links[name] = html\n        \ndf.set_index('Name', inplace=True)\ndf.fillna(2, inplace=True)\ndf.to_csv('comm_noncomm.csv')        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CREATING DATASET FROM COMMERCIAL AND NONCOMMERCIAL LICENSES\n!mkdir comm\n!mkdir noncomm\n\nfor url in all_licenses_links:\n    text = ''\n    wd.get(all_licenses_links[url]+'#fulltext')\n    html = wd.page_source\n    soup = bs(html)\n    texts = soup.find_all(class_='editable')\n    for sent in texts:\n        text += ' ' + sent.text\n     \n    #Check if commercial or noncommercial\n    if df.loc[url]['Commercial Use'] == 1:\n        directory = 'comm'\n    else:\n        directory = 'noncomm'\n    name = re.sub('\\W+','', url )\n    with open(f\"{directory}/{name}.txt\", 'w') as file:\n        file.write(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r comm_noncomm_data noncomm comm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scraping Data from website(trading data)\nurl = 'https://tradingeconomics.com/poland/calendar#'\nwd.get(url)\nhtml = wd.page_source\nsoup = bs(html)\n\nwd.find_element(By.CLASS_NAME, 'btn.btn-default.dropdown-toggle.btn-calendar').click()\nwd.find_element(By.CLASS_NAME, 'glyphicon.glyphicon-pencil').click()\nwd.implicitly_wait(10)\n\n#MAX 1000 records at one time\nstart_date = wd.find_element(By.ID, 'startDate') #From\nstart_date.clear()\nstart_date.send_keys(\"2019-01-01\")\n\nend_date = wd.find_element(By.ID, 'endDate') #Until\nend_date.clear()\nend_date.send_keys(\"2023-01-01\")\n\nwd.find_element(By.CLASS_NAME, 'btn.btn-success').click()\n\ntime_zone = Select(wd.find_element(By.ID, 'DropDownListTimezone'))\ntime_zone.select_by_visible_text('UTC +1') #Timezone\n\nhtml = wd.page_source","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def try_except(success):\n    try:\n        return float(re.sub(\"[^0-9.-]\", \"\", success.text))\n    except:\n        return np.nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"soup = bs(html, 'lxml')\ndf = pd.DataFrame()\ntemp_df = pd.DataFrame()\n\nall_dates = soup.find_all(class_='table-header')\nall_dates = list(map(lambda x: datetime.strptime(' '.join(x.text.split()[1:4]), '%B %d %Y'), all_dates))\n\ntbody_elements = soup.find(id='calendar').find_all('tbody')\ntr_elements = list(map(lambda x: len(x.find_all('tr', {'data-id':True})), tbody_elements))\nnum_events_in_day = list(filter(None, tr_elements))\n\ndate_to_event = np.repeat(all_dates, num_events_in_day)\n\ndata = soup.find_all(\"tr\", {\"data-event\":True})\nfor idx, event in enumerate(data):\n    data_event = event['data-event']\n    actual = try_except(event.find(['a', 'span'], {\"id\":'actual'}))\n    previous = try_except(event.find(['a', 'span'], {\"id\":'previous'}))\n    consensus = try_except(event.find(['a', 'span'], {\"id\":'consensus'}))\n    forecast = try_except(event.find(['a', 'span'], {\"id\":'forecast'}))\n    temp_df[f\"{data_event}-actual\"] = [actual]\n    temp_df[f\"{data_event}-previous\"] = [previous]\n    temp_df[f\"{data_event}-consensus\"] = [consensus]\n    temp_df[f\"{data_event}-forecast\"] = [forecast]\n    temp_df['date'] = [date_to_event[idx]]\n    df = pd.concat([df, temp_df])\n\ndf.set_index('date', inplace=True)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}